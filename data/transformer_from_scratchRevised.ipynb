{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Transformer from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll be implementing the famous Transformer architecture from scratch.\n",
    "\n",
    "The code is based off of the following repos/blog posts:\n",
    "\n",
    "- [attention-is-all-you-need-pytorch](https://github.com/jadore801120/attention-is-all-you-need-pytorch)\n",
    "- [nlp-tutorial](https://github.com/graykode/nlp-tutorial)\n",
    "- [The illustrated Transformer](https://nlpinkorean.github.io/illustrated-transformer/l)\n",
    "\n",
    "Thanks so much to their authors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as npdec_self_attn_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://camo.githubusercontent.com/88e8f36ce61dedfd2491885b8df2f68c4d1f92f5/687474703a2f2f696d6775722e636f6d2f316b72463252362e706e67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['기분이 저기압일 때에는 고기 앞으로 가라 P', 'S eat meat when you feel low ', 'eat meat when you feel low E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = {'P' : 0, '기분이' : 1, '저기압일' : 2, '때에는' : 3, '고기' : 4, '앞으로' : 5, '가라' : 6}\n",
    "src_vocab_size = len(src_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P': 0, '기분이': 1, '저기압일': 2, '때에는': 3, '고기': 4, '앞으로': 5, '가라': 6}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_vocab = {'P' : 0, 'eat' : 1, 'meat' : 2, 'when' : 3, 'you' : 4, 'feel' : 5, 'low' : 6, 'S' : 7, 'E' : 8}\n",
    "tgt_vocab_size = len(tgt_vocab)\n",
    "\n",
    "src_len = 7\n",
    "tgt_len = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input_batch = [[src_vocab[n] for n in sentences[0].split()]]\n",
    "dec_input_batch = [[tgt_vocab[n] for n in sentences[1].split()]]\n",
    "dec_output_batch = [[tgt_vocab[n] for n in sentences[2].split()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4, 5, 6, 0]]\n",
      "[[7, 1, 2, 3, 4, 5, 6]]\n",
      "[[1, 2, 3, 4, 5, 6, 8]]\n"
     ]
    }
   ],
   "source": [
    "print(enc_input_batch)\n",
    "print(dec_input_batch)\n",
    "print(dec_output_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input_batch = Variable(torch.LongTensor(enc_input_batch))\n",
    "dec_input_batch = Variable(torch.LongTensor(dec_input_batch))\n",
    "dec_output_batch = Variable(torch.LongTensor(dec_output_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4, 5, 6, 0]])\n",
      "tensor([[7, 1, 2, 3, 4, 5, 6]])\n",
      "tensor([[1, 2, 3, 4, 5, 6, 8]])\n"
     ]
    }
   ],
   "source": [
    "print(enc_input_batch)\n",
    "print(dec_input_batch)\n",
    "print(dec_output_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super().__init__()        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.weight = nn.Parameter(pe, requires_grad=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.weight[:, :x.size(1), :] # (1, Seq, Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordPositionEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=512):\n",
    "        super().__init__()\n",
    "        self.word_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        return self.word_embedding(x) + self.position_embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_emb = WordPositionEmbedding(src_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordPositionEmbedding(\n",
       "  (word_embedding): Embedding(7, 512)\n",
       "  (position_embedding): PositionalEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_emb = input_emb(enc_input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://camo.githubusercontent.com/88e8f36ce61dedfd2491885b8df2f68c4d1f92f5/687474703a2f2f696d6775722e636f6d2f316b72463252362e706e67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, n_blocks=6, d_model=512, n_heads=8, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoders = nn.ModuleList([\n",
    "            EncoderBlock(d_model=d_model, d_feature=d_model // n_heads, d_ff=d_ff, dropout=dropout)\n",
    "                                                                                                                    for _ in range(n_blocks)])\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "encoder = TransformerEncoder()\n",
    "enc_output_batch = encoder(enc_emb)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model=512, d_feature=64, d_ff=2048, n_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn_head = MultiHeadAttention(d_model, d_feature, n_heads, dropout)\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.position_wise_feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        print('[Encoder Block]')\n",
    "        print(x.shape, \"Encoder block input\")\n",
    "        att = self.attn_head(x, x, x, mask=mask)\n",
    "        print(att.shape, \"Attention output\")\n",
    "        \n",
    "        # Apply normalization and residual connection\n",
    "        x = self.dropout(self.layer_norm1(x + att))\n",
    "        \n",
    "        # Apply position-wise feedforward network\n",
    "        pos = self.position_wise_feed_forward(x)\n",
    "        print(pos.shape, \"Feedforward output\")\n",
    "        \n",
    "        # Apply normalization and residual connection\n",
    "        x = self.dropout(self.layer_norm2(x + pos))\n",
    "        print(x.shape, \"Encoder output\\n\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, d_feature, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_feature = d_feature\n",
    "        \n",
    "        self.W_Q = nn.Linear(d_model, d_feature * n_heads)\n",
    "        self.W_K = nn.Linear(d_model, d_feature * n_heads)\n",
    "        self.W_V = nn.Linear(d_model, d_feature * n_heads)\n",
    "        \n",
    "        self.W_O = nn.Linear(n_heads * d_feature, d_model)\n",
    "        \n",
    "    def forward(self, x1, x2, x3, mask):\n",
    "        print('\\t[MULTIHEAD]')\n",
    "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
    "        residual, batch_size = x1, x1.size(0)\n",
    "        \n",
    "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        Q = self.W_Q(x1).view(batch_size, -1, self.n_heads, self.d_feature).transpose(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
    "        K = self.W_K(x2).view(batch_size, -1, self.n_heads, self.d_feature).transpose(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n",
    "        V = self.W_V(x3).view(batch_size, -1, self.n_heads, self.d_feature).transpose(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n",
    "        print('\\t# Q, K, V shape(batch, heads, length, d_model/heads) :')\n",
    "        print('\\t',Q.shape, K.shape, V.shape)\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
    "\n",
    "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        Z = ScaledDotProductAttention()(Q, K, V, mask, self.d_feature)\n",
    "        print('\\t# Z shape : ', Z.shape)\n",
    "        Z = Z.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_feature) # context: [batch_size x len_q x n_heads * d_v]\n",
    "        print('\\t# Z shape changed : ', Z.shape)\n",
    "        output = self.W_O(Z)\n",
    "        return output # output: [batch_size x len_q x d_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\textrm{Attention}(Q, K, V) = \\textrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        \n",
    "    def forward(self, Q, K, V, attn_mask, d_k):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        print('\\t# scores, V : ', scores.shape, V.shape)\n",
    "        if attn_mask is not None:\n",
    "            scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Encoder Block]\n",
      "torch.Size([1, 7, 512]) Encoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Encoder output\n",
      "\n",
      "[Encoder Block]\n",
      "torch.Size([1, 7, 512]) Encoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Encoder output\n",
      "\n",
      "[Encoder Block]\n",
      "torch.Size([1, 7, 512]) Encoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Encoder output\n",
      "\n",
      "[Encoder Block]\n",
      "torch.Size([1, 7, 512]) Encoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Encoder output\n",
      "\n",
      "[Encoder Block]\n",
      "torch.Size([1, 7, 512]) Encoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Encoder output\n",
      "\n",
      "[Encoder Block]\n",
      "torch.Size([1, 7, 512]) Encoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Encoder output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = TransformerEncoder()\n",
    "enc_output_batch = encoder(enc_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, n_blocks=6, d_model=512, d_feature=64,\n",
    "                 d_ff=2048, n_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.position_embedding = PositionalEmbedding(d_model)\n",
    "        self.decoders = nn.ModuleList([\n",
    "            DecoderBlock(d_model=d_model, d_feature=d_model // n_heads, d_ff=d_ff, dropout=dropout)\n",
    "            for _ in range(n_blocks)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, enc_out, src_mask=None, tgt_mask=None):\n",
    "        for decoder in self.decoders:\n",
    "            x = decoder(x, enc_out, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model=512, d_feature=64, d_ff=2048, n_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.enc_attn_head = MultiHeadAttention(d_model, d_feature, n_heads, dropout)\n",
    "        self.dec_attn_head = MultiHeadAttention(d_model, d_feature, n_heads, dropout)\n",
    "        self.position_wise_feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_out, src_mask=None, tgt_mask=None):\n",
    "        # Apply attention to inputs\n",
    "        print('[Decoder Block]')\n",
    "        print(x.shape, \"Decoder block input\")\n",
    "        att = self.dec_attn_head(x, x, x, mask=src_mask)\n",
    "        print(att.shape, \"First Attention output\")\n",
    "        x = self.dropout(self.layer_norm1(x + att))\n",
    "        \n",
    "        # Apply attention to the encoder outputs and outputs of the previous layer\n",
    "        att = self.dec_attn_head(x1=x, x2=enc_out, x3=enc_out, mask=tgt_mask)\n",
    "        print(att.shape, \"Second Attention output\")\n",
    "        x = self.dropout(self.layer_norm2(x + att))\n",
    "        # Apply position-wise feedforward network\n",
    "        pos = self.position_wise_feed_forward(x)\n",
    "        print(pos.shape, \"Feedforward output\")\n",
    "        x = self.dropout(self.layer_norm2(x + pos))\n",
    "        print(x.shape, \"Decoder output\\n\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_emb = WordPositionEmbedding(tgt_vocab_size)\n",
    "decoder = TransformerDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Decoder Block]\n",
      "torch.Size([1, 7, 512]) Decoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) First Attention output\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Second Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Decoder output\n",
      "\n",
      "[Decoder Block]\n",
      "torch.Size([1, 7, 512]) Decoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) First Attention output\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Second Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Decoder output\n",
      "\n",
      "[Decoder Block]\n",
      "torch.Size([1, 7, 512]) Decoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) First Attention output\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Second Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Decoder output\n",
      "\n",
      "[Decoder Block]\n",
      "torch.Size([1, 7, 512]) Decoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) First Attention output\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Second Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Decoder output\n",
      "\n",
      "[Decoder Block]\n",
      "torch.Size([1, 7, 512]) Decoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) First Attention output\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Second Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Decoder output\n",
      "\n",
      "[Decoder Block]\n",
      "torch.Size([1, 7, 512]) Decoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) First Attention output\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Second Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Decoder output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dec_emb = output_emb(dec_input_batch)\n",
    "result = decoder(dec_emb, enc_output_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 7])\n",
      "tensor([[[0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "enc_self_attn_mask = get_attn_pad_mask(enc_input_batch, enc_input_batch)\n",
    "print(enc_self_attn_mask.shape)\n",
    "print(enc_self_attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_subsequent_mask(seq):\n",
    "    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1)\n",
    "    subsequent_mask = torch.from_numpy(subsequent_mask).byte()\n",
    "    return subsequent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_self_attn_pad_mask = get_attn_pad_mask(dec_input_batch, dec_input_batch)\n",
    "dec_self_attn_subsequent_mask = get_attn_subsequent_mask(dec_input_batch)\n",
    "dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 7])\n",
      "tensor([[[0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(dec_self_attn_pad_mask.shape)\n",
    "print(dec_self_attn_pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 7])\n",
      "tensor([[[0, 1, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(dec_self_attn_subsequent_mask.shape)\n",
    "print(dec_self_attn_subsequent_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(dec_self_attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Encoder Block]\n",
      "torch.Size([1, 7, 512]) Encoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Encoder output\n",
      "\n",
      "[Encoder Block]\n",
      "torch.Size([1, 7, 512]) Encoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Encoder output\n",
      "\n",
      "[Encoder Block]\n",
      "torch.Size([1, 7, 512]) Encoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Encoder output\n",
      "\n",
      "[Encoder Block]\n",
      "torch.Size([1, 7, 512]) Encoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Encoder output\n",
      "\n",
      "[Encoder Block]\n",
      "torch.Size([1, 7, 512]) Encoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Encoder output\n",
      "\n",
      "[Encoder Block]\n",
      "torch.Size([1, 7, 512]) Encoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Encoder output\n",
      "\n",
      "[Decoder Block]\n",
      "torch.Size([1, 7, 512]) Decoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) First Attention output\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Second Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Decoder output\n",
      "\n",
      "[Decoder Block]\n",
      "torch.Size([1, 7, 512]) Decoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) First Attention output\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Second Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Decoder output\n",
      "\n",
      "[Decoder Block]\n",
      "torch.Size([1, 7, 512]) Decoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) First Attention output\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Second Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Decoder output\n",
      "\n",
      "[Decoder Block]\n",
      "torch.Size([1, 7, 512]) Decoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) First Attention output\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Second Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Decoder output\n",
      "\n",
      "[Decoder Block]\n",
      "torch.Size([1, 7, 512]) Decoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) First Attention output\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Second Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Decoder output\n",
      "\n",
      "[Decoder Block]\n",
      "torch.Size([1, 7, 512]) Decoder block input\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) First Attention output\n",
      "\t[MULTIHEAD]\n",
      "\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n",
      "\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n",
      "\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape :  torch.Size([1, 8, 7, 64])\n",
      "\t# Z shape changed :  torch.Size([1, 7, 512])\n",
      "torch.Size([1, 7, 512]) Second Attention output\n",
      "torch.Size([1, 7, 512]) Feedforward output\n",
      "torch.Size([1, 7, 512]) Decoder output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = TransformerEncoder()\n",
    "enc_output_batch = encoder(enc_emb, enc_self_attn_mask)\n",
    "\n",
    "output_emb = WordPositionEmbedding(tgt_vocab_size)\n",
    "decoder = TransformerDecoder()\n",
    "\n",
    "dec_emb = output_emb(dec_input_batch)\n",
    "result = decoder(dec_emb, enc_output_batch, src_mask=enc_self_attn_mask, tgt_mask= dec_self_attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
